"""
Steganalysis Detection System for Text-in-Image Steganography

This module implements various detection and analysis techniques to identify
and characterize hidden text in images generated by steganographic methods.

Components:
1. Binary Text Detector - Determines if an image contains hidden text
2. Capacity Estimator - Predicts the amount of hidden text
3. Text Type Classifier - Distinguishes between plain text and encrypted text
4. Feature Extractor - Extracts statistical and visual features for analysis
5. Performance Analyzer - Generates ROC curves and performance metrics
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Dict, List, Optional
import cv2
from sklearn.metrics import roc_curve, auc, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import re
import string
from collections import Counter


@dataclass
class SteganalysisResult:
    """Results from steganalysis detection."""
    has_hidden_text: bool
    confidence_score: float
    estimated_capacity: int
    text_type: str  # 'plain', 'encrypted', 'unknown'
    features: Dict[str, float]
    

class ImageFeatureExtractor(nn.Module):
    """Extracts statistical and visual features from images for steganalysis."""
    
    def __init__(self):
        super().__init__()
        
        # CNN feature extractor
        self.cnn_features = nn.Sequential(
            # First conv block
            nn.Conv2d(3, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # Second conv block
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # Third conv block
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # Global average pooling
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten()
        )
        
        # Statistical feature processor
        self.stat_processor = nn.Sequential(
            nn.Linear(12, 32),  # 12 statistical features
            nn.ReLU(inplace=True),
            nn.Linear(32, 64),
            nn.ReLU(inplace=True)
        )
        
        # Feature fusion
        self.feature_fusion = nn.Sequential(
            nn.Linear(128 + 64, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, 128)
        )
    
    def extract_statistical_features(self, image: torch.Tensor) -> torch.Tensor:
        """Extract statistical features from image."""
        batch_size = image.size(0)
        features = []
        
        for i in range(batch_size):
            img = image[i].cpu().numpy().transpose(1, 2, 0)
            
            # Color channel statistics
            r_mean, g_mean, b_mean = img[:,:,0].mean(), img[:,:,1].mean(), img[:,:,2].mean()
            r_std, g_std, b_std = img[:,:,0].std(), img[:,:,1].std(), img[:,:,2].std()
            
            # Gradient magnitude
            gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            grad_mean = grad_magnitude.mean()
            grad_std = grad_magnitude.std()
            
            # Noise estimation (high-frequency components)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            noise_var = laplacian.var()
            
            # Entropy
            hist, _ = np.histogram(gray, bins=256, range=(0, 256))
            hist = hist / hist.sum()
            entropy = -np.sum(hist * np.log2(hist + 1e-10))
            
            stat_features = [
                r_mean, g_mean, b_mean, r_std, g_std, b_std,
                grad_mean, grad_std, noise_var, entropy,
                img.mean(), img.std()
            ]
            features.append(stat_features)
        
        return torch.tensor(features, dtype=torch.float32, device=image.device)
    
    def forward(self, image: torch.Tensor) -> torch.Tensor:
        """Extract combined features from image."""
        # CNN features
        cnn_feat = self.cnn_features(image)
        
        # Statistical features
        stat_feat = self.extract_statistical_features(image)
        stat_feat = self.stat_processor(stat_feat)
        
        # Combine features
        combined_feat = torch.cat([cnn_feat, stat_feat], dim=1)
        return self.feature_fusion(combined_feat)


class BinaryTextDetector(nn.Module):
    """Binary classifier to detect presence of hidden text."""
    
    def __init__(self, feature_dim: int = 128):
        super().__init__()
        
        self.feature_extractor = ImageFeatureExtractor()
        
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )
    
    def forward(self, image: torch.Tensor) -> torch.Tensor:
        """Forward pass for binary classification."""
        features = self.feature_extractor(image)
        logits = self.classifier(features)
        return torch.sigmoid(logits)


class CapacityEstimator(nn.Module):
    """Estimates the amount of hidden text in an image."""
    
    def __init__(self, feature_dim: int = 128, max_capacity: int = 100):
        super().__init__()
        
        self.feature_extractor = ImageFeatureExtractor()
        self.max_capacity = max_capacity
        
        self.regressor = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, 1)
        )
    
    def forward(self, image: torch.Tensor) -> torch.Tensor:
        """Estimate text capacity."""
        features = self.feature_extractor(image)
        capacity = self.regressor(features)
        return torch.clamp(capacity, 0, self.max_capacity)


class TextTypeClassifier(nn.Module):
    """Classifies the type of hidden text (plain vs encrypted)."""
    
    def __init__(self, feature_dim: int = 128):
        super().__init__()
        
        self.feature_extractor = ImageFeatureExtractor()
        
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(32, 3)  # plain, encrypted, unknown
        )
    
    def forward(self, image: torch.Tensor) -> torch.Tensor:
        """Classify text type."""
        features = self.feature_extractor(image)
        logits = self.classifier(features)
        return F.softmax(logits, dim=1)


class TextPatternAnalyzer:
    """Analyzes extracted text for linguistic patterns."""
    
    def __init__(self):
        self.english_freq = {
            'e': 12.70, 't': 9.06, 'a': 8.17, 'o': 7.51, 'i': 6.97,
            'n': 6.75, 's': 6.33, 'h': 6.09, 'r': 5.99, 'd': 4.25,
            'l': 4.03, 'c': 2.78, 'u': 2.76, 'm': 2.41, 'w': 2.36,
            'f': 2.23, 'g': 2.02, 'y': 1.97, 'p': 1.93, 'b': 1.29,
            'v': 0.98, 'k': 0.77, 'j': 0.15, 'x': 0.15, 'q': 0.10,
            'z': 0.07
        }
    
    def analyze_text(self, text: str) -> Dict[str, float]:
        """Analyze text for linguistic patterns."""
        if not text:
            return {}
        
        text_lower = text.lower()
        
        # Character frequency analysis
        char_counts = Counter(c for c in text_lower if c.isalpha())
        total_chars = sum(char_counts.values())
        
        if total_chars == 0:
            return {'is_encrypted': 1.0, 'entropy': 0.0, 'randomness': 1.0}
        
        # Calculate chi-squared test against English
        chi_squared = 0
        for char in 'abcdefghijklmnopqrstuvwxyz':
            observed = (char_counts.get(char, 0) / total_chars) * 100
            expected = self.english_freq.get(char, 0.01)
            chi_squared += ((observed - expected) ** 2) / expected
        
        # Entropy calculation
        char_probs = [count / total_chars for count in char_counts.values()]
        entropy = -sum(p * np.log2(p) for p in char_probs if p > 0)
        
        # Randomness indicators
        vowel_ratio = sum(char_counts.get(v, 0) for v in 'aeiou') / total_chars
        consonant_ratio = 1 - vowel_ratio
        
        # Word patterns
        words = re.findall(r'\b[a-zA-Z]+\b', text)
        avg_word_length = np.mean([len(w) for w in words]) if words else 0
        
        # Determine if likely encrypted
        is_encrypted = (chi_squared > 50 or entropy > 4.0 or 
                       vowel_ratio < 0.2 or vowel_ratio > 0.6)
        
        return {
            'chi_squared': chi_squared,
            'entropy': entropy,
            'vowel_ratio': vowel_ratio,
            'consonant_ratio': consonant_ratio,
            'avg_word_length': avg_word_length,
            'is_encrypted': float(is_encrypted),
            'randomness': min(chi_squared / 100, 1.0)
        }


class SteganalysisSystem:
    """Complete steganalysis system for text-in-image detection."""
    
    def __init__(self, device: str = 'cpu'):
        self.device = device
        
        # Initialize models
        self.detector = BinaryTextDetector().to(device)
        self.capacity_estimator = CapacityEstimator().to(device)
        self.type_classifier = TextTypeClassifier().to(device)
        self.text_analyzer = TextPatternAnalyzer()
        
        # Performance tracking
        self.detection_history = []
        self.performance_metrics = {}
    
    def analyze_image(self, image: torch.Tensor, 
                     extracted_text: Optional[str] = None) -> SteganalysisResult:
        """Complete analysis of a potentially steganographic image."""
        
        with torch.no_grad():
            # Binary detection
            has_text_prob = self.detector(image).item()
            has_hidden_text = has_text_prob > 0.5
            
            # Capacity estimation
            estimated_capacity = int(self.capacity_estimator(image).item())
            
            # Text type classification
            type_probs = self.type_classifier(image).squeeze()
            text_types = ['plain', 'encrypted', 'unknown']
            text_type = text_types[torch.argmax(type_probs).item()]
            
            # Feature extraction
            features = self.detector.feature_extractor(image).squeeze().cpu().numpy()
            feature_dict = {f'feature_{i}': float(features[i]) for i in range(min(10, len(features)))}
            
            # Text analysis if available
            if extracted_text:
                text_features = self.text_analyzer.analyze_text(extracted_text)
                feature_dict.update(text_features)
                
                # Override type classification with text analysis
                if 'is_encrypted' in text_features and text_features['is_encrypted'] > 0.5:
                    text_type = 'encrypted'
                elif text_features.get('chi_squared', 0) < 30:
                    text_type = 'plain'
        
        return SteganalysisResult(
            has_hidden_text=has_hidden_text,
            confidence_score=has_text_prob,
            estimated_capacity=estimated_capacity,
            text_type=text_type,
            features=feature_dict
        )
    
    def batch_analysis(self, images: torch.Tensor, 
                      texts: Optional[List[str]] = None) -> List[SteganalysisResult]:
        """Analyze multiple images."""
        results = []
        
        for i in range(images.size(0)):
            image = images[i:i+1]
            text = texts[i] if texts else None
            result = self.analyze_image(image, text)
            results.append(result)
            
        return results
    
    def evaluate_performance(self, test_images: torch.Tensor, 
                           ground_truth: List[bool],
                           test_texts: Optional[List[str]] = None) -> Dict[str, float]:
        """Evaluate detection performance and generate metrics."""
        
        results = self.batch_analysis(test_images, test_texts)
        predictions = [r.confidence_score for r in results]
        binary_preds = [r.has_hidden_text for r in results]
        
        # Calculate metrics
        true_positives = sum(1 for i, pred in enumerate(binary_preds) 
                           if pred and ground_truth[i])
        true_negatives = sum(1 for i, pred in enumerate(binary_preds) 
                           if not pred and not ground_truth[i])
        false_positives = sum(1 for i, pred in enumerate(binary_preds) 
                            if pred and not ground_truth[i])
        false_negatives = sum(1 for i, pred in enumerate(binary_preds) 
                            if not pred and ground_truth[i])
        
        accuracy = (true_positives + true_negatives) / len(ground_truth)
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # ROC curve
        fpr, tpr, _ = roc_curve(ground_truth, predictions)
        roc_auc = auc(fpr, tpr)
        
        # Precision-recall curve
        precision_curve, recall_curve, _ = precision_recall_curve(ground_truth, predictions)
        pr_auc = auc(recall_curve, precision_curve)
        
        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'roc_auc': roc_auc,
            'pr_auc': pr_auc,
            'true_positives': true_positives,
            'true_negatives': true_negatives,
            'false_positives': false_positives,
            'false_negatives': false_negatives
        }
        
        self.performance_metrics = metrics
        return metrics
    
    def plot_roc_curves(self, test_data: Dict[str, Tuple[torch.Tensor, List[bool]]], 
                       save_path: Optional[str] = None):
        """Plot ROC curves for different test scenarios."""
        
        plt.figure(figsize=(12, 8))
        
        for scenario_name, (images, labels) in test_data.items():
            results = self.batch_analysis(images)
            predictions = [r.confidence_score for r in results]
            
            fpr, tpr, _ = roc_curve(labels, predictions)
            roc_auc = auc(fpr, tpr)
            
            plt.plot(fpr, tpr, linewidth=2, 
                    label=f'{scenario_name} (AUC = {roc_auc:.3f})')
        
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for Text Steganography Detection')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_detection_report(self, results: List[SteganalysisResult]) -> str:
        """Generate a comprehensive detection report."""
        
        total_images = len(results)
        detected_images = sum(1 for r in results if r.has_hidden_text)
        avg_confidence = np.mean([r.confidence_score for r in results])
        avg_capacity = np.mean([r.estimated_capacity for r in results])
        
        type_counts = Counter(r.text_type for r in results)
        
        report = f"""
# Steganalysis Detection Report

## Summary Statistics
- **Total Images Analyzed**: {total_images}
- **Images with Hidden Text**: {detected_images} ({detected_images/total_images*100:.1f}%)
- **Clean Images**: {total_images - detected_images} ({(total_images-detected_images)/total_images*100:.1f}%)
- **Average Detection Confidence**: {avg_confidence:.3f}
- **Average Estimated Capacity**: {avg_capacity:.1f} characters

## Text Type Distribution
"""
        
        for text_type, count in type_counts.items():
            percentage = count / total_images * 100
            report += f"- **{text_type.title()}**: {count} images ({percentage:.1f}%)\n"
        
        report += f"""

## Performance Metrics
"""
        
        if self.performance_metrics:
            for metric, value in self.performance_metrics.items():
                if isinstance(value, float):
                    report += f"- **{metric.replace('_', ' ').title()}**: {value:.3f}\n"
                else:
                    report += f"- **{metric.replace('_', ' ').title()}**: {value}\n"
        
        return report
    
    def save_model_weights(self, save_dir: str):
        """Save trained model weights."""
        import os
        os.makedirs(save_dir, exist_ok=True)
        
        torch.save(self.detector.state_dict(), 
                  os.path.join(save_dir, 'binary_detector.pth'))
        torch.save(self.capacity_estimator.state_dict(), 
                  os.path.join(save_dir, 'capacity_estimator.pth'))
        torch.save(self.type_classifier.state_dict(), 
                  os.path.join(save_dir, 'type_classifier.pth'))
    
    def load_model_weights(self, load_dir: str):
        """Load pre-trained model weights."""
        import os
        
        detector_path = os.path.join(load_dir, 'binary_detector.pth')
        capacity_path = os.path.join(load_dir, 'capacity_estimator.pth')
        type_path = os.path.join(load_dir, 'type_classifier.pth')
        
        if os.path.exists(detector_path):
            self.detector.load_state_dict(torch.load(detector_path, map_location=self.device))
        if os.path.exists(capacity_path):
            self.capacity_estimator.load_state_dict(torch.load(capacity_path, map_location=self.device))
        if os.path.exists(type_path):
            self.type_classifier.load_state_dict(torch.load(type_path, map_location=self.device))


def create_training_data_for_steganalysis(steganography_system, num_samples: int = 1000):
    """Create training data for steganalysis by generating steganographic images."""
    
    training_images = []
    training_labels = []
    training_texts = []
    
    # Generate positive samples (with hidden text)
    for i in range(num_samples // 2):
        # Generate random text
        text_length = np.random.randint(10, 50)
        if np.random.random() > 0.5:
            # Plain text
            text = ''.join(np.random.choice(list(string.ascii_letters + ' '), text_length))
        else:
            # Encrypted-like text
            text = ''.join(np.random.choice(list(string.ascii_letters + string.digits), text_length))
        
        # Generate steganographic image (placeholder)
        # In practice, you would use your trained steganography system
        image = torch.randn(3, 32, 32)  # Placeholder
        
        training_images.append(image)
        training_labels.append(True)
        training_texts.append(text)
    
    # Generate negative samples (clean images)
    for i in range(num_samples // 2):
        image = torch.randn(3, 32, 32)  # Clean image placeholder
        
        training_images.append(image)
        training_labels.append(False)
        training_texts.append("")
    
    return torch.stack(training_images), training_labels, training_texts


if __name__ == "__main__":
    # Example usage
    print("Initializing Steganalysis System...")
    
    steganalysis = SteganalysisSystem(device='cpu')
    
    # Create sample data
    test_images, test_labels, test_texts = create_training_data_for_steganalysis(None, 100)
    
    print("Running steganalysis evaluation...")
    
    # Analyze sample images
    results = steganalysis.batch_analysis(test_images[:10], test_texts[:10])
    
    # Generate performance metrics
    metrics = steganalysis.evaluate_performance(test_images, test_labels, test_texts)
    
    # Generate report
    report = steganalysis.generate_detection_report(results)
    print(report)
    
    print("\nSteganalysis system demonstration completed!")
